{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from datetime import timedelta\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "random.seed(1)\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Data/time_b_df_decay.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m time_b_df_decay = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mData/time_b_df_decay.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m time_b_df_growth =pd.read_csv(\u001b[33m'\u001b[39m\u001b[33mData/time_b_df_growth.csv\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      3\u001b[39m time_b_df_normal = pd.read_csv(\u001b[33m'\u001b[39m\u001b[33mData/time_b_df_normal.csv\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'Data/time_b_df_decay.csv'"
     ]
    }
   ],
   "source": [
    "time_b_df_decay = pd.read_csv('Data/time_b_df_decay.csv')\n",
    "time_b_df_growth =pd.read_csv('Data/time_b_df_growth.csv')\n",
    "time_b_df_normal = pd.read_csv('Data/time_b_df_normal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "class DriftDetector:\n",
    "    def __init__(self, baseline_data, window_size=7, threshold_drop=1):\n",
    "        \"\"\"\n",
    "        Lightweight Bayesian drift detector using Gaussian likelihood scoring.\n",
    "\n",
    "        Parameters:\n",
    "        - baseline_data: np.array or pd.Series of engagement from Time A\n",
    "        - window_size: number of days in each scoring window\n",
    "        - threshold_drop: log-likelihood drop threshold to signal drift\n",
    "        \"\"\"\n",
    "        self.window_size = window_size\n",
    "        self.threshold_drop = threshold_drop\n",
    "        self.mu = np.mean(baseline_data)\n",
    "        self.sigma = np.std(baseline_data)\n",
    "        self.fitted = True\n",
    "\n",
    "    def compute_log_likelihood(self, window):\n",
    "        return np.sum(norm.logpdf(window, loc=self.mu, scale=self.sigma))\n",
    "\n",
    "    def detect(self, time_b_series):\n",
    "        \"\"\"\n",
    "        Slides a window over Time B and returns the first changepoint (if any).\n",
    "        \"\"\"\n",
    "        log_likelihoods = []\n",
    "        changepoint = None\n",
    "\n",
    "        for i in range(0, len(time_b_series) - self.window_size):\n",
    "            window = time_b_series[i:i + self.window_size]\n",
    "            ll = self.compute_log_likelihood(window)\n",
    "            log_likelihoods.append(ll)\n",
    "\n",
    "            if i >= 5:\n",
    "                prev_avg = np.mean(log_likelihoods[max(0, i-5):i])\n",
    "                if prev_avg - ll > self.threshold_drop:\n",
    "                    changepoint = i + self.window_size\n",
    "                    break\n",
    "\n",
    "        return changepoint, log_likelihoods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_group_drift_detection(group_name, time_a_df, time_b_df, window_size=7, threshold_drop=1):\n",
    "    group_a = time_a_df[time_a_df['Group'] == group_name]['Engagement'].values\n",
    "    group_b = time_b_df[time_b_df['Group'] == group_name]['Engagement'].values\n",
    "\n",
    "    detector = DriftDetector(baseline_data=group_a, window_size=window_size, threshold_drop=threshold_drop)\n",
    "    changepoint, ll_trace = detector.detect(group_b)\n",
    "\n",
    "    return changepoint, ll_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_all_groups(time_a_df, time_b_df, time_b_start_date, window_size=7, threshold_drop=1):\n",
    "    group_results = {}\n",
    "    for group in ['Baseline', 'Drifters', 'Power Users']:\n",
    "        cp_index, _ = run_group_drift_detection(group, time_a_df, time_b_df, window_size, threshold_drop)\n",
    "\n",
    "        if cp_index is not None:\n",
    "            cp_date = pd.to_datetime(time_b_start_date) + pd.Timedelta(days=cp_index)\n",
    "        else:\n",
    "            cp_date = \"Not Detected\"\n",
    "\n",
    "        group_results[group] = {\n",
    "            \"changepoint_index\": cp_index,\n",
    "            \"changepoint_date\": cp_date\n",
    "        }\n",
    "\n",
    "    return group_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_log_likelihoods(ll_trace, title=\"Log-Likelihood Drift Detection\"):\n",
    "    plt.plot(ll_trace)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Window Index\")\n",
    "    plt.ylabel(\"Log-Likelihood\")\n",
    "    plt.axvline(np.argmax(np.diff(ll_trace)), color='red', linestyle='--')\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group = \"Power Users\"  # or \"Baseline\", or \"Drifters\"\n",
    "\n",
    "# # Extract engagement values for the selected group from Time A and Time B\n",
    "# group_a = time_a_df[time_a_df['Group'] == group]['Engagement'].values\n",
    "# group_b = time_b_df_decay[time_b_df_decay['Group'] == group]['Engagement'].values\n",
    "\n",
    "# print(f\"üîç Analyzing group: {group}\")\n",
    "# print(f\"Time A size: {len(group_a)}, Time B size: {len(group_b)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detector = DriftDetector(baseline_data=group_a, window_size=7, threshold_drop=1)\n",
    "# changepoint, ll_trace = detector.detect(group_b)\n",
    "\n",
    "# print(f\"Changepoint: {changepoint}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.plot(ll_trace)\n",
    "# plt.axhline(np.mean(ll_trace[:5]), color='red', linestyle='--', label=\"Early Avg\")\n",
    "# plt.title(f\"Log-Likelihood Drift Trace for {group}\")\n",
    "# plt.xlabel(\"Window Index\")\n",
    "# plt.ylabel(\"Log-Likelihood\")\n",
    "# plt.grid(True)\n",
    "# plt.legend()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = evaluate_all_groups(time_a_df, time_b_df_decay, \"2024-07-01\")\n",
    "# for group, info in results.items():\n",
    "#     print(f\"{group} ‚ûú Detected changepoint: {info['changepoint_date']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_group_drift_detection(time_b_df, results, time_b_start_date):\n",
    "    time_b_df = time_b_df.copy()\n",
    "    time_b_df['Date'] = pd.to_datetime(time_b_df['Date'])\n",
    "\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(18, 5), sharey=True)\n",
    "\n",
    "    for i, group in enumerate(['Baseline', 'Drifters', 'Power Users']):\n",
    "        group_df = time_b_df[time_b_df['Group'] == group]\n",
    "        group_df['Month'] = group_df['Date'].dt.to_period('M').astype(str)\n",
    "\n",
    "        ax = axs[i]\n",
    "        sns.boxplot(data=group_df, x='Month', y='Engagement', ax=ax)\n",
    "        ax.set_title(f\"Group = {group}\")\n",
    "        ax.set_xticklabels(ax.get_xticklabels(), rotation=45)\n",
    "\n",
    "        # Mark true changepoint\n",
    "        true_cp_date = pd.to_datetime(time_b_start_date)\n",
    "        ax.axvline(x=0, color='green', linestyle='--', label='True Drift Start')\n",
    "\n",
    "        # Mark detected changepoint\n",
    "        cp_index = results[group][\"changepoint_index\"]\n",
    "        if cp_index is not None:\n",
    "            detected_cp_date = pd.to_datetime(time_b_start_date) + pd.Timedelta(days=cp_index)\n",
    "            ax.axvline(\n",
    "                x=(detected_cp_date.to_period('M') - true_cp_date.to_period('M')).n, \n",
    "                color='red', linestyle='-', label='Detected Drift'\n",
    "            )\n",
    "\n",
    "        if i == 0:\n",
    "            ax.set_ylabel(\"Engagement\")\n",
    "        else:\n",
    "            ax.set_ylabel(\"\")\n",
    "\n",
    "    handles, labels = axs[0].get_legend_handles_labels()\n",
    "    fig.legend(handles, labels, loc='upper center', ncol=2)\n",
    "    fig.suptitle(\"üìà Monthly Engagement + Drift Detection Lines\", fontsize=14)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_group_drift_detection_lineplot(time_b_df, results, time_b_start_date):\n",
    "    time_b_df = time_b_df.copy()\n",
    "    time_b_df['Date'] = pd.to_datetime(time_b_df['Date'])\n",
    "\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(18, 5), sharey=True)\n",
    "\n",
    "    for i, group in enumerate(['Baseline', 'Drifters', 'Power Users']):\n",
    "        group_df = time_b_df[time_b_df['Group'] == group].copy()\n",
    "\n",
    "        # Group by day, use daily mean (you could also use median)\n",
    "        daily_engagement = group_df.groupby('Date')['Engagement'].mean()\n",
    "\n",
    "        ax = axs[i]\n",
    "        ax.plot(daily_engagement.index, daily_engagement.values, label=\"Engagement\", color='blue')\n",
    "        ax.set_title(f\"Group: {group}\")\n",
    "        ax.set_xlabel(\"Date\")\n",
    "        if i == 0:\n",
    "            ax.set_ylabel(\"Engagement\")\n",
    "\n",
    "        # True drift start\n",
    "        true_cp_date = pd.to_datetime(time_b_start_date)\n",
    "        ax.axvline(x=true_cp_date, color='green', linestyle='--', label='True Drift Start')\n",
    "\n",
    "        # Detected drift\n",
    "        cp_index = results[group][\"changepoint_index\"]\n",
    "        if cp_index is not None:\n",
    "            detected_cp_date = true_cp_date + pd.Timedelta(days=cp_index)\n",
    "            ax.axvline(x=detected_cp_date, color='red', linestyle='-', label='Detected Drift')\n",
    "\n",
    "        ax.grid(True)\n",
    "        ax.legend()\n",
    "\n",
    "    fig.suptitle(\"üìâ Daily Engagement with Drift Detection per Group\", fontsize=14)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_decay = evaluate_all_groups(time_a_df, time_b_df_decay, \"2024-07-01\", window_size=7, threshold_drop=1)\n",
    "results_growth = evaluate_all_groups(time_a_df, time_b_df_growth, \"2024-07-01\", window_size=7, threshold_drop=1)\n",
    "results_normal = evaluate_all_groups(time_a_df, time_b_df_normal, \"2024-07-01\", window_size=7, threshold_drop=1)\n",
    "\n",
    "# Plot line plots for each:\n",
    "plot_group_drift_detection_lineplot(time_b_df_decay, results_decay, \"2024-07-01\")\n",
    "plot_group_drift_detection_lineplot(time_b_df_growth, results_growth, \"2024-07-01\")\n",
    "plot_group_drift_detection_lineplot(time_b_df_normal, results_normal, \"2024-07-01\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
